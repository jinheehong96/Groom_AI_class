{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN 기반 Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#import torchvision\n",
    "import torch.optim as optim\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import tqdm\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# for reproducibility\n",
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: Wikipedia wikitree dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "with urllib.request.urlopen('https://raw.githubusercontent.com/yunjey/pytorch-tutorial/master/tutorials/02-intermediate/language_model/data/train.txt') as f:\n",
    "    data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_sentence: 42068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b\" plans that give advertisers discounts for maintaining or increasing ad spending have become permanent <unk> at the news <unk> and underscore the fierce competition between newsweek time warner inc. 's time magazine and <unk> b. <unk> 's u.s. news & world report \\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('num_sentence:', len(data))\n",
    "data[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length_list = [] #data list에 넣기\n",
    "for line in data:\n",
    "    seq_length_list.append(len(line.split()))\n",
    "\n",
    "counts, bins = np.histogram(seq_length_list, bins=20)\n",
    "plt.hist(bins[:-1], bins, weights=counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 50 #문장 길이 최대 50"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어 dictionary 만들기 (함수 build dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dictionary(data, max_seq_len):\n",
    "    word2idx = {}\n",
    "    idx2word = {}\n",
    "    ## Build Dictionary\n",
    "    word2idx['<pad>'] = 0\n",
    "    word2idx['<unk>'] = 1 \n",
    "    idx2word[0] , idx2word[1] = '<pad>', '<unk>'\n",
    "    idx =2\n",
    "    for line in data:\n",
    "        words = line.decode('utf-8').split()\n",
    "        words = words[:max_seq_len]\n",
    "        for word in words:\n",
    "            if word not in word2idx:\n",
    "                word2idx[word] = idx\n",
    "                idx2word[idx] = word \n",
    "                idx += 1\n",
    "                \n",
    "    return word2idx, idx2word\n",
    "\n",
    "word2idx, idx2word = build_dictionary(data, max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Passed!\n"
     ]
    }
   ],
   "source": [
    "if len(word2idx) == len(idx2word) == 10000:\n",
    "    print('Test Passed!')\n",
    "else:\n",
    "    raise AssertionError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data, word2idx, idx2word, max_seq_len):\n",
    "    tokens = []\n",
    "    for line in data:\n",
    "        words = line.decode('utf-8').split()\n",
    "        words = words[:max_seq_len]\n",
    "        words += ['<pad>']*(max_seq_len - len(words))\n",
    "        for word in words:\n",
    "            token = word2idx[word]\n",
    "            tokens.append(token)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "tokens = preprocess(data, word2idx, idx2word, max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Passed!\n"
     ]
    }
   ],
   "source": [
    "if len(tokens) == 2103400:\n",
    "    print(\"Test Passed!\")\n",
    "else:\n",
    "    raise AssertionError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42068, 50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([745,  93, 746, 739, 747, 181, 748, 467, 749, 740, 750, 154, 751,\n",
       "       752,   1, 160,  32, 753,   1,  48, 754,  32, 755, 756, 757, 728,\n",
       "       555, 758,  99, 119, 555, 733,  48,   1, 759,   1, 119, 237, 753,\n",
       "       230, 760, 347,   0,   0,   0,   0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = np.array(tokens).reshape(-1, max_seq_len)\n",
    "print(tokens.shape)\n",
    "tokens[100]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokens):\n",
    "        super(LMDataset, self).__init__()\n",
    "        self.PAD = 0\n",
    "        self.UNK = 1\n",
    "        self.tokens = tokens\n",
    "        self._getitem(2)\n",
    "    \n",
    "    def _getitem(self, index):\n",
    "        X = self.tokens[index]\n",
    "        y = np.concatenate((X[1:], [self.PAD]))\n",
    "\n",
    "        X = torch.from_numpy(X).unsqueeze(0).long()\n",
    "        y = torch.from_numpy(y).unsqueeze(0).long()\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.tokens[index]\n",
    "        y = np.concatenate((X[1:], [self.PAD]))\n",
    "\n",
    "        X = torch.from_numpy(X).long()\n",
    "        y = torch.from_numpy(y).long()\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokens)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42068\n",
      "658\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "dataset = LMDataset(tokens)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(len(dataset))\n",
    "print(len(dataloader))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Model\n",
    "RNN (Recurrent Neural Network) 구조인 LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module): #hidden layer에 해당하는 부분을 만든 것\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(LSTMCell, self).__init__()\n",
    "        self.Wi = nn.Linear(input_size +hidden_size, hidden_size) #input gate\n",
    "        self.Wf = nn.Linear(input_size + hidden_size, hidden_size) #forget-gate\n",
    "        self.Wg = nn.Linear(input_size + hidden_size, hidden_size) #gate-gate\n",
    "        self.Wo = nn.Linear(input_size + hidden_size, hidden_size) #output-gate\n",
    "    \n",
    "    def forward(self, x, h_0, c_0):\n",
    "        \"\"\"\n",
    "        Inputs\n",
    "            input (x): [batch_size, input_size]\n",
    "            hidden_state (h_0): [batch_size, hidden_size]\n",
    "            cell_state (c_0): [batch_size, hidden_size]\n",
    "        Outputs\n",
    "            next_hidden_state (h_1): [batch_size, hidden_size]\n",
    "            next_cell_state (c_1): [batch_size, hidden_size]    \n",
    "        \"\"\"\n",
    "        h_1, c_1 = None, None\n",
    "        input = torch.cat((x, h_0), 1)\n",
    "        \n",
    "        i = self.sigmoid(self.Wi(input))\n",
    "        f = self.sigmoid(self.Wf(input))\n",
    "        g = self.tanh(self.Wg(input))\n",
    "        o = self.sigmoid(self.Wo(input))\n",
    "        \n",
    "        c_1 = f* c_0 + i*g \n",
    "        h_1 = o * self.tanh(c_1)\n",
    "        \n",
    "        return h_1, c_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self, input_size=64, hidden_size=64, vocab_size= 10000):\n",
    "        super(LanguageModel, self).__init__()\n",
    "        \n",
    "        self.input_layer = nn.Embedding(vocab_size, input_size)\n",
    "        self.hidden_layer = LSTMCell(input_size, hidden_size)\n",
    "        self.output_layer = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "    def forward(self, x, hx, cx, predict= False):\n",
    "        x = self.input_layer(x)\n",
    "        hx, cx = self.hidden_layer(x, hx, cx)\n",
    "        ox = self.output_layer(hx)\n",
    "        \n",
    "        if predict == True:\n",
    "            probs = F.softmax(ox, dim=1)\n",
    "            dist = torch.distributions.Categorical(probs)\n",
    "            ox = dist.sample()\n",
    "        \n",
    "        return ox, hx, cx #out, hidden, cell state\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__( self, word2idx, idx2word, dataloader,hidden_size, model, criterion, optimizer, device):\n",
    "        self.word2idx = word2idx\n",
    "        self.idx2word = idx2word \n",
    "        self.dataloader = dataloader\n",
    "        self.hiddensize = hidden_size\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        \n",
    "    def train(self, epochs = 1):\n",
    "        self.model.to(self.device)\n",
    "        start_time = time.time()\n",
    "        for epoch in range(epochs):\n",
    "            losses = []  #loss 저장하기 위함\n",
    "            for iter, (x_batch, y_batch) in tqdm.tqdm(enumerate(self.dataloader)):\n",
    "                self.model.train()\n",
    "                \n",
    "                batch_size, max_seq_len = x_batch.shape\n",
    "                x_batch = x_batch.to(self.device)\n",
    "                y_batch = y_batch.to(self.device)\n",
    "                \n",
    "                  # initial hidden-states\n",
    "                hx = torch.zeros(batch_size, self.hidden_size).to(self.device)\n",
    "                cx = torch.zeros(batch_size, self.hidden_size).to(self.device)\n",
    "\n",
    "                # Implement LSTM operation\n",
    "                ox_batch = []\n",
    "                for s_idx in range(max_seq_len):\n",
    "                    x = x_batch[:, s_idx]\n",
    "                    ox, hx, cx = self.model(x, hx, cx)\n",
    "                    ox_batch.append(ox)\n",
    "                # outputs are ordered by the time sequence\n",
    "                ox_batch = torch.cat(ox_batch).reshape(max_seq_len, batch_size, -1)\n",
    "                ox_batch = ox_batch.permute(1,0,2).reshape(batch_size*max_seq_len, -1)\n",
    "                y_batch = y_batch.reshape(-1)\n",
    "\n",
    "                ##train start \n",
    "                self.model.zero_grad() #back prop 하기 전에 모델의 parameter값 초기화\n",
    "                loss = self.criterion(ox_batch, y_batch)\n",
    "                loss.backward() #backprop, 여기가 gradient 다시 update하는 곳\n",
    "                self.optimizer.step()\n",
    "                losses.append(loss.item()) # loss 값 저장                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "input_size, hidden_size, batch_size =128, 128, 256\n",
    "\n",
    "dataset = LMDataset(tokens)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, shuffle=True)\n",
    "model = LanguageModel(input_size=input_size, hidden_size= hidden_size)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer=  optim.Adam(model.parameters(), lr=lr)\n",
    "device = torch.device('cuda')\n",
    "\n",
    "trainer = Trainer(word2idx = word2idx,\n",
    "                  idx2word = idx2word,\n",
    "                  dataloader=dataloader, \n",
    "                  model = model,\n",
    "                  criterion=criterion,\n",
    "                  optimizer = optimizer,\n",
    "                  device=device)\n",
    "\n",
    "trainer.train(epochs=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
